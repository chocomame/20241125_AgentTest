import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd
import re
from urllib.parse import urlparse, unquote
from utils import normalize_url, is_preview_url, get_all_links
from checkers import (
    check_html_syntax,
    check_heading_order,
    check_image_alt,
    check_keyword_repetition
)

def get_page_info(url):
    """ãƒšãƒ¼ã‚¸ã®ã‚¿ã‚¤ãƒˆãƒ«ã¨ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ã‚’å–å¾—"""
    try:
        # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼URLã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if is_preview_url(url):
            return {
                'url': normalize_url(url),
                'title': "ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼URLï¼‰",
                'description': "ã‚¹ã‚­ãƒƒãƒ—ï¼ˆãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼URLï¼‰",
                'title_length': 0,
                'description_length': 0,
                'title_status': '- ã‚¹ã‚­ãƒƒãƒ—',
                'description_status': '- ã‚¹ã‚­ãƒƒãƒ—',
                'heading_issues': '- ã‚¹ã‚­ãƒƒãƒ—',
                'english_only_headings': '- ã‚¹ã‚­ãƒƒãƒ—',
                'images_without_alt': '- ã‚¹ã‚­ãƒƒãƒ—',
                'html_syntax': '- ã‚¹ã‚­ãƒƒãƒ—',
                'status_code': 0,
                'related_urls': []  # é–¢é€£URLã®ãƒªã‚¹ãƒˆã‚’è¿½åŠ 
            }

        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(url, headers=headers, timeout=10)
        
        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®è‡ªå‹•æ¤œå‡ºã¨è¨­å®š
        if response.encoding == 'ISO-8859-1':
            response.encoding = response.apparent_encoding
        elif 'charset' in response.headers.get('content-type', '').lower():
            response.encoding = response.apparent_encoding
        else:
            response.encoding = 'utf-8'
        
        # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’ä¿å­˜
        status_code = response.status_code
        
        # 404ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ç‰¹åˆ¥ãªçµæœã‚’è¿”ã™
        if status_code == 404:
            return {
                'url': normalize_url(url),
                'title': "404 ã‚¨ãƒ©ãƒ¼",
                'description': "ãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“",
                'title_length': 0,
                'description_length': 0,
                'title_status': 'âŒ 404ã‚¨ãƒ©ãƒ¼',
                'description_status': 'âŒ 404ã‚¨ãƒ©ãƒ¼',
                'heading_issues': 'âŒ 404ã‚¨ãƒ©ãƒ¼',
                'english_only_headings': 'âŒ 404ã‚¨ãƒ©ãƒ¼',
                'images_without_alt': 'âŒ 404ã‚¨ãƒ©ãƒ¼',
                'html_syntax': 'âŒ 404ã‚¨ãƒ©ãƒ¼',
                'status_code': 404,
                'related_urls': []  # é–¢é€£URLã®ãƒªã‚¹ãƒˆã‚’è¿½åŠ 
            }
        
        response.raise_for_status()
        html_content = response.text
        
        # BeautifulSoupã§ãƒ‘ãƒ¼ã‚¹ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æŒ‡å®šï¼‰
        soup = BeautifulSoup(html_content, 'html.parser', from_encoding=response.encoding)
        
        # æ­£è¦åŒ–ã•ã‚ŒãŸURLã‚’ä½¿ç”¨
        normalized_url = normalize_url(url)
        
        result = {
            'url': normalized_url,
            'title': "å–å¾—ã‚¨ãƒ©ãƒ¼",
            'description': "å–å¾—ã‚¨ãƒ©ãƒ¼",
            'title_length': 0,
            'description_length': 0,
            'title_status': 'âŒ ã‚¨ãƒ©ãƒ¼',
            'description_status': 'âŒ ã‚¨ãƒ©ãƒ¼',
            'heading_issues': 'âŒ ã‚¨ãƒ©ãƒ¼',
            'english_only_headings': 'âŒ ã‚¨ãƒ©ãƒ¼',
            'images_without_alt': 'âŒ ã‚¨ãƒ©ãƒ¼',
            'html_syntax': 'âŒ ã‚¨ãƒ©ãƒ¼',
            'status_code': status_code,
            'related_urls': []  # é–¢é€£URLã®ãƒªã‚¹ãƒˆã‚’è¿½åŠ 
        }
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã®å–å¾—ã¨é‡è¤‡ãƒã‚§ãƒƒã‚¯
        try:
            title = soup.title.string.strip() if soup.title else "ã‚¿ã‚¤ãƒˆãƒ«ãªã—"
            # ã‚¿ã‚¤ãƒˆãƒ«ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç¢ºèªã—ã¦ä¿®æ­£
            if isinstance(title, bytes):
                title = title.decode(response.encoding)
            title_repetitions = check_keyword_repetition(title)
            title_status = []
            
            # é•·ã•ãƒã‚§ãƒƒã‚¯
            if len(title) > 50:
                title_status.append('âŒ é•·ã™ãã¾ã™ï¼ˆ50æ–‡å­—ä»¥å†…æ¨å¥¨ï¼‰')
            
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            if title_repetitions:
                title_status.append(f'âš ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®é‡è¤‡: {", ".join(title_repetitions)}')
            
            # å•é¡ŒãŒãªã„å ´åˆ
            if not title_status:
                title_status = ['âœ… OK']
            
            result.update({
                'title': title,
                'title_length': len(title),
                'title_status': '<br>'.join(title_status)
            })
        except Exception:
            pass
        
        # ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ã®å–å¾—ã¨é‡è¤‡ãƒã‚§ãƒƒã‚¯
        try:
            description = ""
            meta_desc = soup.find('meta', attrs={'name': re.compile('^[Dd]escription$')})
            if meta_desc:
                description = meta_desc.get('content', '').strip()
            
            if not description:
                og_desc = soup.find('meta', attrs={'property': 'og:description'})
                if og_desc:
                    description = og_desc.get('content', '').strip()
            
            # ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’ç¢ºèªã—ã¦ä¿®æ­£
            if isinstance(description, bytes):
                description = description.decode(response.encoding)
            
            description_repetitions = check_keyword_repetition(description)
            description_status = []
            
            # é•·ã•ãƒã‚§ãƒƒã‚¯
            if len(description) > 140:
                description_status.append('âŒ é•·ã™ãã¾ã™ï¼ˆ140æ–‡å­—ä»¥å†…æ¨å¥¨ï¼‰')
            
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            if description_repetitions:
                description_status.append(f'âš ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®é‡è¤‡: {", ".join(description_repetitions)}')
            
            # å•é¡ŒãŒãªã„å ´åˆ
            if not description_status:
                description_status = ['âœ… OK']
            
            result.update({
                'description': description,
                'description_length': len(description),
                'description_status': '<br>'.join(description_status)
            })
        except Exception:
            pass
        
        # è¦‹å‡ºã—æ§‹é€ ã®ãƒã‚§ãƒƒã‚¯
        try:
            heading_issues, english_only_headings = check_heading_order(soup)
            result['heading_issues'] = '<br>'.join(heading_issues) if heading_issues else 'âœ… OK'
            result['english_only_headings'] = '<br>'.join(english_only_headings) if english_only_headings else 'âœ… OK'
        except Exception:
            pass
        
        # ç”»åƒã®altå±æ€§ãƒã‚§ãƒƒã‚¯
        try:
            alt_check_result = check_image_alt(soup, url)
            result['images_without_alt'] = alt_check_result
        except Exception:
            pass
        
        # HTMLæ§‹æ–‡ãƒã‚§ãƒƒã‚¯
        try:
            syntax_errors = check_html_syntax(html_content)
            result['html_syntax'] = syntax_errors[0]
            
            # é–¢é€£URLã‚’æŠ½å‡ºï¼ˆã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ï¼‰
            if 'https://' in result['html_syntax']:
                related_urls = re.findall(r'https://[^\s<>"\']+', result['html_syntax'])
                result['related_urls'] = related_urls
        except Exception:
            pass
        
        return result
        
    except requests.RequestException:
        return {
            'url': normalize_url(url),
            'title': "æ¥ç¶šãƒ©ãƒ¼",
            'description': "æ¥ç¶šã‚¨ãƒ©ãƒ¼",
            'title_length': 0,
            'description_length': 0,
            'title_status': 'âŒ æ¥ç¶šã‚¨ãƒ©ãƒ¼',
            'description_status': 'âŒ æ¥ç¶šã‚¨ãƒ©ãƒ¼',
            'heading_issues': 'âŒ æ¥ç¶šã‚¨ãƒ©ãƒ¼',
            'english_only_headings': 'âŒ æ¥ç¶šã‚¨ãƒ©ãƒ¼',
            'images_without_alt': 'âŒ æ¥ç¶šã‚¨ãƒ©ãƒ¼',
            'html_syntax': 'âŒ æ¥ç¶šã‚¨ãƒ©ãƒ¼',
            'status_code': 0,
            'related_urls': []  # é–¢é€£URLã®ãƒªã‚¹ãƒˆã‚’è¿½åŠ 
        }

def main():
    # ãƒšãƒ¼ã‚¸å¹…ã®è¨­å®š
    st.set_page_config(
        page_title="æ¤œå“ãƒã‚§ãƒƒã‚¯6é¸",
        layout="wide",
        initial_sidebar_state="auto"
    )

    # ã‚«ã‚¹ã‚¿ãƒ CSS
    st.markdown("""
        <style>
        .block-container {
            max-width: 1104px;
            padding-top: 1rem;
            padding-bottom: 1rem;
        }
        </style>
    """, unsafe_allow_html=True)

    st.title("ğŸ” æ¤œå“ãƒã‚§ãƒƒã‚¯6é¸")
    
    # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã¨å¤‰æ›´å±¥æ­´
    with st.expander("ğŸ“‹ ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã¨å¤‰æ›´å±¥æ­´"):
        st.write("""
        **ç¾åœ¨ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³: v1.0.0** ğŸš€ (2024.11.26 ãƒªãƒªãƒ¼ã‚¹)
        
        **å¤‰æ›´å±¥æ­´ï¼š**
        - v1.0.0 (2024.11.26)
          - âœ¨ åˆå›ãƒªãƒªãƒ¼ã‚¹
          - ğŸ¯ åŸºæœ¬çš„ãªSEOè¦ç´ ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ã‚’å®Ÿè£…
        - v0.9.0 (2024.11.25)
          - ğŸ”§ ãƒ™ãƒ¼ã‚¿ç‰ˆãƒªãƒªãƒ¼ã‚¹
          - ğŸ§ª ãƒ†ã‚¹ãƒˆé‹ç”¨é–‹å§‹
        """)
    
    # ãƒã‚§ãƒƒã‚¯é …ç›®
    with st.expander("ğŸ“Š ãƒã‚§ãƒƒã‚¯é …ç›®ã®è©³ç´°"):
        st.write("""
        1. ğŸ“ ã‚¿ã‚¤ãƒˆãƒ«ã‚¿ã‚°
           - æ–‡å­—æ•°ï¼ˆ50æ–‡å­—ä»¥å†…ï¼‰
           - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆè¨ºç™‚ç§‘åã‚’é™¤ãï¼‰
           - è¨ºç™‚ç§‘åã¯é‡è¤‡ã‚’è¨±å®¹

        2. ğŸ“„ ãƒ¡ã‚¿ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³
           - æ–‡å­—æ•°ï¼ˆ140æ–‡å­—ä»¥å†…ï¼‰
           - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆè¨ºç™‚ç§‘åã‚’é™¤ãï¼‰
           - è¨ºç™‚ç§‘åã¯é‡è¤‡ã‚’è¨±å®¹

        3. ğŸ“‘ è¦‹å‡ºã—æ§‹é€ ï¼ˆh1ã€œh6ã®éšå±¤é–¢ä¿‚ï¼‰
           - è¦‹å‡ºã—ãƒ¬ãƒ™ãƒ«ã®é©åˆ‡ãªéšå±¤æ§‹é€ 
           - é£›ã³éšå±¤ã®ãƒã‚§ãƒƒã‚¯

        4. ğŸ–¼ï¸ ç”»åƒã®altå±æ€§
           - ä»£æ›¿ãƒ†ã‚­ã‚¹ãƒˆã®æœ‰ç„¡
           - ãƒ–ãƒ­ã‚°ãƒ»ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒšãƒ¼ã‚¸ã¯ã‚¹ã‚­ãƒƒãƒ—

        5. ğŸ”§ HTMLæ§‹æ–‡
           - é–‰ã˜ã‚¿ã‚°ã®æœ‰ç„¡
           - ã‚¿ã‚°ã®æ­£ç¢ºæ€§ãƒã‚§ãƒƒã‚¯

        6. âš ï¸ 404ã‚¨ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸
           - å­˜åœ¨ã—ãªã„ãƒšãƒ¼ã‚¸ã®æ¤œå‡º
           - ãƒªãƒ³ã‚¯åˆ‡ã‚Œã®ç¢ºèª
        """)
    
    # ä½¿ã„æ–¹
    with st.expander("ğŸš€ ä½¿ã„æ–¹"):
        st.write("""
        1. ğŸ”— ãƒã‚§ãƒƒã‚¯ã—ãŸã„ã‚¦ã‚§ãƒ–ã‚µã‚¤ãƒˆã®URLã‚’å…¥åŠ›
        2. â–¶ ã€Œãƒã‚§ãƒƒã‚¯é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
        3. âœ¨ è‡ªå‹•çš„ã«å…¨ãƒšãƒ¼ã‚¸ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€çµæœã‚’è¡¨ç¤º
        """)
    
    # å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
    url = st.text_input("ğŸŒ ãƒã‚§ãƒƒã‚¯ã—ãŸã„WEBã‚µã‚¤ãƒˆã®URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", "")
    
    if st.button("ğŸ” ãƒã‚§ãƒƒã‚¯é–‹å§‹") and url:
        base_domain = urlparse(url).netloc
        
        with st.spinner('ğŸ”„ ã‚µã‚¤ãƒˆã‚’ãƒã‚§ãƒƒã‚¯ä¸­...'):
            # è¨ªå•æ¸ˆã¿URLã‚’ç®¡ç†
            visited_urls = set()
            urls_to_visit = {url}
            results = []
            not_found_pages = []  # 404ãƒšãƒ¼ã‚¸ã‚’è¨˜éŒ²
            
            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®åˆæœŸåŒ–
            progress_bar = st.progress(0)
            
            while urls_to_visit:
                current_url = urls_to_visit.pop()
                normalized_current_url = normalize_url(current_url)
                
                if normalized_current_url not in visited_urls:
                    visited_urls.add(normalized_current_url)
                    
                    # ãƒšãƒ¼ã‚¸æƒ…å ±ã®å–å¾—
                    page_info = get_page_info(current_url)
                    
                    # 404ã‚¨ãƒ©ãƒ¼ã®ãƒšãƒ¼ã‚¸ã‚’è¨˜éŒ²
                    if page_info and page_info.get('status_code') == 404:
                        not_found_pages.append(page_info)
                    # 404ä»¥å¤–ã®ãƒšãƒ¼ã‚¸ã‚’çµæœã«è¿½åŠ 
                    elif page_info is not None:
                        results.append(page_info)
                    
                    # æ–°ã—ã„ãƒªãƒ³ã‚¯ã®å–å¾—ï¼ˆ404ãƒšãƒ¼ã‚¸ä»¥å¤–ï¼‰
                    if page_info and page_info.get('status_code') != 404:
                        try:
                            response = requests.get(current_url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=10)
                            soup = BeautifulSoup(response.text, 'html.parser')
                            new_links = get_all_links(current_url, base_domain, soup)
                            urls_to_visit.update(new_links - visited_urls)
                        except Exception:
                            pass
                
                # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®æ›´æ–°
                progress = len(visited_urls) / (len(visited_urls) + len(urls_to_visit))
                progress_bar.progress(min(progress, 1.0))
            
            # çµæœã®è¡¨ç¤º
            if results or not_found_pages:
                df = pd.DataFrame(results)
                not_found_df = pd.DataFrame(not_found_pages) if not_found_pages else None
                
                st.write(f"âœ… ãƒã‚§ãƒƒã‚¯å®Œäº†ï¼ åˆè¨ˆ{len(results)}ãƒšãƒ¼ã‚¸ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã—ãŸã€‚")
                if not_found_pages:
                    st.write(f"âš ï¸ {len(not_found_pages)}ä»¶ã®404ã‚¨ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚")
                
                # ã‚¿ãƒ–ã§çµæœã‚’è¡¨ç¤º
                tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
                    "ğŸ“ ã‚¿ã‚¤ãƒˆãƒ«ãƒ»ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³",
                    "ğŸ“‘ è¦‹å‡ºã—æ§‹é€ ",
                    "ğŸ”¤ è‹±èªã®ã¿ã®è¦‹å‡ºã—",
                    "ğŸ–¼ï¸ ç”»åƒaltå±æ€§",
                    "ğŸ”§ HTMLæ§‹æ–‡",
                    "âš ï¸ 404ã‚¨ãƒ©ãƒ¼"
                ])
                
                with tab1:
                    st.subheader("ğŸ“Š ã‚¿ã‚¤ãƒˆãƒ«ã¨ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ã®ãƒã‚§ãƒƒã‚¯")
                    st.markdown("""
                        <style>
                        .dataframe a {
                            color: #1E88E5;
                            text-decoration: underline;
                        }
                        .dataframe td {
                            max-width: 300px;
                            white-space: normal !important;
                            padding: 8px !important;
                            vertical-align: top;
                        }
                        .dataframe th {
                            padding: 8px !important;
                            background-color: #f8f9fa;
                        }
                        .status-ok {
                            color: #28a745;
                            font-weight: bold;
                        }
                        .status-error {
                            color: #dc3545;
                            font-weight: bold;
                        }
                        .length-info {
                            color: #6c757d;
                            font-size: 0.9em;
                        }
                        </style>
                    """, unsafe_allow_html=True)
                    
                    # ãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢
                    display_df = df.copy()
                    display_df['url'] = display_df['url'].apply(
                        lambda x: f'<a href="{x}" target="_blank">{unquote(x, encoding="utf-8")}</a>'
                    )
                    display_df['title'] = display_df.apply(
                        lambda row: f"{row['title']}<br><span class='length-info'>({row['title_length']}æ–‡å­—)</span>", 
                        axis=1
                    )
                    display_df['description'] = display_df.apply(
                        lambda row: f"{row['description']}<br><span class='length-info'>({row['description_length']}æ–‡å­—)</span>", 
                        axis=1
                    )
                    
                    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¯ãƒ©ã‚¹ã¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¨­å®š
                    def format_status(status_text):
                        if 'âœ… OK' in status_text:
                            return f'<span class="status-ok">{status_text}</span>'
                        elif 'âŒ' in status_text:
                            return f'<span class="status-error">{status_text}</span>'
                        elif 'âš ï¸' in status_text:
                            return f'<span class="status-warning">{status_text}</span>'
                        return status_text

                    display_df['status'] = display_df.apply(
                        lambda row: (
                            f"ã‚¿ã‚¤ãƒˆãƒ«: {format_status(row['title_status'])}<br>" +
                            f"ãƒ‡ã‚£ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³: {format_status(row['description_status'])}"
                        ),
                        axis=1
                    )
                    
                    # è¡¨ç¤ºã™ã‚‹ã‚«ãƒ©ãƒ ã‚’é¸æŠ
                    st.write(display_df[['url', 'title', 'description', 'status']].to_html(
                        escape=False, index=False), unsafe_allow_html=True)
                
                with tab2:
                    st.subheader("ğŸ“‘ è¦‹å‡ºã—æ§‹é€ ã®ãƒã‚§ãƒƒã‚¯")
                    # URLã‚«ãƒ©ãƒ ã«ãƒªãƒ³ã‚¯ã‚’è¿½åŠ 
                    display_df2 = df.copy()
                    display_df2['url'] = display_df2['url'].apply(
                        lambda x: f'<a href="{x}" target="_blank">{unquote(x, encoding="utf-8")}</a>'
                    )
                    st.write(display_df2[['url', 'heading_issues']].to_html(escape=False, index=False), unsafe_allow_html=True)
                
                with tab3:
                    st.subheader("ğŸ”¤ è‹±èªã®ã¿ã®è¦‹å‡ºã—ã®ãƒã‚§ãƒƒã‚¯")
                    # URLã‚«ãƒ©ãƒ ã«ãƒªãƒ³ã‚¯ã‚’è¿½åŠ 
                    display_df3 = df.copy()
                    display_df3['url'] = display_df3['url'].apply(
                        lambda x: f'<a href="{x}" target="_blank">{unquote(x, encoding="utf-8")}</a>'
                    )
                    st.write(display_df3[['url', 'english_only_headings']].to_html(escape=False, index=False), unsafe_allow_html=True)
                
                with tab4:
                    st.subheader("ğŸ–¼ï¸ altå±æ€§ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ç”»åƒ")
                    # ã‚«ã‚¹ã‚¿ãƒ CSSã‚’è¿½åŠ 
                    st.markdown("""
                        <style>
                        .dataframe td {
                            max-width: 500px;
                            white-space: normal !important;
                            word-wrap: break-word;
                            word-break: break-all;
                        }
                        .dataframe th {
                            white-space: normal !important;
                            word-wrap: break-word;
                            word-break: break-all;
                        }
                        </style>
                    """, unsafe_allow_html=True)
                    
                    # URLã‚«ãƒ©ãƒ ã«ãƒªãƒ³ã‚¯ã‚’è¿½åŠ 
                    display_df4 = df.copy()
                    display_df4['url'] = display_df4['url'].apply(
                        lambda x: f'<a href="{x}" target="_blank">{unquote(x, encoding="utf-8")}</a>'
                    )
                    # ç”»åƒURLã‚’ã‚¯ãƒªãƒƒã‚¯å¯èƒ½ãªãƒªãƒ³ã‚¯ã«å¤‰æ›
                    display_df4['images_without_alt'] = display_df4['images_without_alt'].apply(
                        lambda x: x if x in ['âœ… OK', '- ç”»åƒãªã—', 'skip'] else
                        '<br>'.join([
                            f'{line.split(": ")[0]}: <a href="{line.split(": ")[1]}" target="_blank">{line.split(": ")[1]}</a>'
                            for line in x.split('\n')[1:]  # æœ€åˆã®è¡Œï¼ˆâŒ altå±æ€§ãªã—:ï¼‰ã‚’ã‚¹ã‚­ãƒƒãƒ—
                        ])
                    )
                    st.write(display_df4[['url', 'images_without_alt']].to_html(escape=False, index=False), unsafe_allow_html=True)
                
                with tab5:
                    st.subheader("ğŸ”§ HTMLæ§‹æ–‡ãƒã‚§ãƒƒã‚¯")
                    
                    # ã‚«ã‚¹ã‚¿ãƒ CSSã‚’è¿½åŠ 
                    st.markdown("""
                        <style>
                        .html-error {
                            color: #dc3545;
                            margin-bottom: 8px;
                        }
                        .html-ok {
                            color: #28a745;
                            font-weight: bold;
                            margin: 0;
                            padding: 0;
                            line-height: 1;
                        }
                        .error-line {
                            color: #666;
                            margin-left: 20px;
                            display: block;
                            font-family: monospace;
                        }
                        .error-tag {
                            color: #e83e8c;
                            background-color: #f8f9fa;
                            padding: 2px 4px;
                            border-radius: 3px;
                            font-family: monospace;
                        }
                        td {
                            vertical-align: middle !important;
                            padding: 8px !important;
                        }
                        </style>
                    """, unsafe_allow_html=True)
                    
                    # URLã‚«ãƒ©ãƒ ã«ãƒªãƒ³ã‚¯ã‚’è¿½åŠ 
                    display_df5 = df.copy()
                    
                    # HTMLæ§‹æ–‡ã‚¨ãƒ©ãƒ¼ã®è¡¨ç¤ºã‚’æ•´å½¢
                    def format_html_syntax(row):
                        html_syntax = row['html_syntax']
                        
                        if html_syntax == 'âœ… OK':
                            return '<div class="html-ok">âœ… OK</div>'
                        
                        # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ”¹è¡Œã§åˆ†å‰²
                        lines = html_syntax.split('\n')
                        if len(lines) >= 2:
                            main_error = lines[0]  # "âŒ è­¦å‘Š: divã‚¿ã‚°ã®é–‰ã˜å¿˜ã‚ŒãŒ1å€‹ã‚ã‚Šã¾ã™:"
                            detail_line = lines[1]  # "â†’ è¡Œ 470: <div class='xxx'>"
                            
                            # è¡Œç•ªå·ã¨ã‚¿ã‚°ã‚’åˆ†é›¢
                            line_parts = detail_line.split(': ', 1)
                            if len(line_parts) == 2:
                                line_info, tag_content = line_parts
                                formatted_error = f'<div class="html-error">{main_error}</div>'
                                formatted_error += f'<span class="error-line">{line_info}: <span class="error-tag">{tag_content}</span></span>'
                                return formatted_error
                        
                        return html_syntax
                    
                    # URLã‚’ãƒªãƒ³ã‚¯ã«å¤‰æ›
                    display_df5['url'] = display_df5['url'].apply(
                        lambda x: f'<a href="{x}" target="_blank">{unquote(x, encoding="utf-8")}</a>'
                    )
                    
                    # HTMLæ§‹æ–‡ã‚¨ãƒ©ãƒ¼ã‚’æ•´å½¢
                    display_df5['html_syntax'] = display_df5.apply(format_html_syntax, axis=1)
                    
                    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¡¨ç¤º
                    st.write(display_df5[['url', 'html_syntax']].to_html(
                        escape=False, 
                        index=False,
                        classes=['dataframe'],
                        table_id='html-syntax-table'
                    ), unsafe_allow_html=True)
                
                with tab6:
                    st.subheader("âš ï¸ 404ã‚¨ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸")
                    if not_found_df is not None and not not_found_df.empty:
                        # URLã‚«ãƒ©ãƒ ã«ãƒªãƒ³ã‚¯ã‚’è¿½åŠ 
                        not_found_df['url'] = not_found_df['url'].apply(
                            lambda x: f'<a href="{x}" target="_blank">{unquote(x, encoding="utf-8")}</a>'
                        )
                        st.write(not_found_df[['url']].to_html(escape=False, index=False), unsafe_allow_html=True)
                    else:
                        st.write("âœ… 404ã‚¨ãƒ©ãƒ¼ãƒšãƒ¼ã‚¸ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                st.write("ãƒã‚§ãƒƒã‚¯å¯èƒ½ãªãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

def get_status_class(status):
    """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã«å¿œã˜ãŸCSSã‚¯ãƒ©ã‚¹ã‚’è¿”ã™"""
    if 'âœ…' in status or 'OK' in status:
        return 'status-ok'
    return 'status-error'

if __name__ == "__main__":
    main() 